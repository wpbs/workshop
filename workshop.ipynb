{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Game-time!\" data-toc-modified-id=\"Game-time!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Game time!</a></span><ul class=\"toc-item\"><li><span><a href=\"#De-opzet\" data-toc-modified-id=\"De-opzet-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>De opzet</a></span></li><li><span><a href=\"#De-winnaar\" data-toc-modified-id=\"De-winnaar-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>De winnaar</a></span></li></ul></li><li><span><a href=\"#De-opdracht\" data-toc-modified-id=\"De-opdracht-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>De opdracht</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stap-1---inlezen-van-modules\" data-toc-modified-id=\"Stap-1---inlezen-van-modules-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Stap 1 - inlezen van modules</a></span></li><li><span><a href=\"#Stap-2---inlezen-van-de-data\" data-toc-modified-id=\"Stap-2---inlezen-van-de-data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Stap 2 - inlezen van de data</a></span></li><li><span><a href=\"#Stap-3---inspecteren-van-de-data\" data-toc-modified-id=\"Stap-3---inspecteren-van-de-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Stap 3 - inspecteren van de data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Beschikbare-kolommen\" data-toc-modified-id=\"Beschikbare-kolommen-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Beschikbare kolommen</a></span></li><li><span><a href=\"#Eerste-rijen\" data-toc-modified-id=\"Eerste-rijen-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Eerste rijen</a></span></li><li><span><a href=\"#Laatste-rijen\" data-toc-modified-id=\"Laatste-rijen-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Laatste rijen</a></span></li><li><span><a href=\"#Datatypes\" data-toc-modified-id=\"Datatypes-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Datatypes</a></span></li><li><span><a href=\"#Globale-statistieken\" data-toc-modified-id=\"Globale-statistieken-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Globale statistieken</a></span></li></ul></li><li><span><a href=\"#Stap-4---data-analyse\" data-toc-modified-id=\"Stap-4---data-analyse-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Stap 4 - data analyse</a></span><ul class=\"toc-item\"><li><span><a href=\"#Groeperen\" data-toc-modified-id=\"Groeperen-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Groeperen</a></span></li><li><span><a href=\"#Grafieken\" data-toc-modified-id=\"Grafieken-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Grafieken</a></span></li></ul></li><li><span><a href=\"#Stap-5---feature-constructie-(skip)\" data-toc-modified-id=\"Stap-5---feature-constructie-(skip)-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Stap 5 - feature constructie (skip)</a></span></li><li><span><a href=\"#Stap-6---basismodel-trainen\" data-toc-modified-id=\"Stap-6---basismodel-trainen-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Stap 6 - basismodel trainen</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-klaarzetten\" data-toc-modified-id=\"Data-klaarzetten-2.6.1\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span>Data klaarzetten</a></span></li><li><span><a href=\"#Model-trainen\" data-toc-modified-id=\"Model-trainen-2.6.2\"><span class=\"toc-item-num\">2.6.2&nbsp;&nbsp;</span>Model trainen</a></span></li></ul></li><li><span><a href=\"#Stap-X---analyse-/-Stap-X+1---feature-constructie\" data-toc-modified-id=\"Stap-X---analyse-/-Stap-X+1---feature-constructie-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Stap X - analyse / Stap X+1 - feature constructie</a></span></li><li><span><a href=\"#Stap-X+2---model-trainen\" data-toc-modified-id=\"Stap-X+2---model-trainen-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Stap X+2 - model trainen</a></span></li><li><span><a href=\"#Stap-[laatste]---eindscore\" data-toc-modified-id=\"Stap-[laatste]---eindscore-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>Stap [laatste] - eindscore</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game time!\n",
    "\n",
    "In deze workshop is het de bedoeling om een zo goed mogelijk model te trainen voor de Titanic dataset. Deze dataset bevat informatie over de overlevenden van de ramp met de Titanic. Het doel is om te kunnen voorspellen wie van de passagiers die in de testset zitten zouden overleven, op basis van het model getraind op de informatie van passagiers in de trainingset (waarvan bekend is of ze het overleefd hebben).\n",
    "\n",
    "## De opzet\n",
    "\n",
    "Deze workshop is zo opgezet dat er een basismodel al is gegeven. Het doel is om dit basismodel zo goed mogelijk te verbeteren door het kiezen van de juiste variabelen, parameters en algoritmes.\n",
    "\n",
    "## De winnaar\n",
    "\n",
    "De winnaar van de challenge is de persoon met de hoogste score en die daarbij kan uitleggen hoe deze tot stand is gekomen.\n",
    "\n",
    "# De opdracht\n",
    "\n",
    "Op 15 april 1912 bij haar eerste vaart is de Titanic gezonken na een akkefietje met een stuk ijs. Hierbij kwamen 1502 van de 2224 passagiers om het leven (32% heeft het dus overleefd). Een van de redenen waarom het percentage overlevenden zo laag ligt is het gebrek aan reddingsboten voor de passagiers en de bemanning. Hoewel er ook een klein aandeel 'geluk' bij betrokken was met betrekking tot de overlevingskansen, waren bepaalde groepen waarschijnlijker om te overleven dan anderen. Denk hierbij aan vrouwen, kinderen en de upper-class.\n",
    "\n",
    "## Stap 1 - inlezen van modules\n",
    "\n",
    "Om een model te kunnen bouwen is het nodig om een aantal bestaande modules (eenmalig) in te laden. Om dit te doen ga je met je cursor in onderstaande cel staan en druk je op [shift]+[enter]. Hiermee kun je 1 enkele cel uitvoeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Helpers:\n",
    "    def add_title(self, train_df, test_df, original_train_df, original_test_df, combine, replacements, title_mapping):\n",
    "        # Haal alle onderdelen eruit\n",
    "        train_df['Title'] = original_train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        test_df['Title'] = original_train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "        # Vervang te specifieke namen door meer algemene namen\n",
    "        for dataset in combine:\n",
    "            for key, value in replacements.items():\n",
    "                dataset['Title'] = dataset['Title'].replace(key, value)\n",
    "\n",
    "        for dataset in combine:\n",
    "            dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "            dataset['Title'] = dataset['Title'].fillna(0)\n",
    "        \n",
    "        print(train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
    "        \n",
    "        return train_df, test_df, combine\n",
    "\n",
    "    def add_age_binned(self, train_df, test_df, original_train_df, original_test_df, combine):\n",
    "        guess_ages = np.zeros((2,3))\n",
    "    \n",
    "        train_df['Sex'] = original_train_df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "        test_df['Sex'] = original_test_df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "        train_df['Age'] = original_train_df['Age']\n",
    "        test_df['Age'] = original_test_df['Age']\n",
    "\n",
    "        for dataset in [train_df, test_df]:\n",
    "            for i in range(0, 2):\n",
    "                for j in range(0, 3):\n",
    "                    guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "                    age_guess = guess_df.median()\n",
    "                    guess_ages[i,j] = int(age_guess/0.5 + 0.5) * 0.5 # Convert random age float to nearest .5 age\n",
    "            for i in range(0, 2):\n",
    "                for j in range(0, 3):\n",
    "                    dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i,j]\n",
    "            dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "        print(\">> schattingen\")\n",
    "        print(train_df.head())\n",
    "\n",
    "        # TODO: aantal bins als parameter meegeven\n",
    "        train_df['AgeBand'] = pd.cut(original_train_df['Age'], 5)\n",
    "\n",
    "        print()\n",
    "        print(\">> Leeftijds-bin\")\n",
    "        print(train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True))\n",
    "\n",
    "        for dataset in combine:    \n",
    "            dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "            dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "            dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "            dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "            dataset.loc[ dataset['Age'] > 64, 'Age']\n",
    "\n",
    "        train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "        combine = [train_df, test_df]\n",
    "        \n",
    "        return train_df, test_df, combine\n",
    "    \n",
    "    def add_age_times_class(self, train_df, test_df, original_train_df, original_test_df, combine):\n",
    "        train_df['Age'] = original_train_df['Age']\n",
    "        train_df.loc[train_df.Age.isnull(), 'Age'] = 0\n",
    "\n",
    "        test_df['Age'] = original_test_df['Age']\n",
    "        test_df.loc[test_df.Age.isnull(), 'Age'] = 0\n",
    "\n",
    "        train_df['Age*Class'] = train_df.Age * original_train_df.Pclass\n",
    "        test_df['Age*Class'] = test_df.Age * original_train_df.Pclass\n",
    "\n",
    "        train_df = train_df.drop(\"Age\", axis=1)\n",
    "        test_df = test_df.drop(\"Age\", axis=1)\n",
    "        \n",
    "        return train_df, test_df, combine\n",
    "    \n",
    "    def add_family_size(self, train_df, test_df, original_train_df, original_test_df, combine):\n",
    "        train_df['SibSp'] = original_train_df['SibSp']\n",
    "        test_df['SibSp'] = original_test_df['SibSp']\n",
    "        train_df['Parch'] = original_train_df['Parch']\n",
    "        test_df['Parch'] = original_test_df['Parch']\n",
    "\n",
    "        for dataset in combine:\n",
    "            dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "        print(train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
    "\n",
    "        train_df = train_df.drop(['Parch', 'SibSp'], axis=1)\n",
    "        test_df = test_df.drop(['Parch', 'SibSp'], axis=1)\n",
    "        combine = [train_df, test_df]\n",
    "        \n",
    "        return train_df, test_df, combine\n",
    "    \n",
    "    def add_is_alone(self, train_df, test_df, original_train_df, original_test_df, combine):\n",
    "        train_df['SibSp'] = original_train_df['SibSp']\n",
    "        test_df['SibSp'] = original_test_df['SibSp']\n",
    "        train_df['Parch'] = original_train_df['Parch']\n",
    "        test_df['Parch'] = original_test_df['Parch']\n",
    "\n",
    "        for dataset in combine:\n",
    "            dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "            dataset['IsAlone'] = 0\n",
    "            dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "        print(train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n",
    "\n",
    "        train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "        test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "        combine = [train_df, test_df]\n",
    "        \n",
    "        return train_df, test_df, combine\n",
    "    \n",
    "    def prepare_dataset(self):\n",
    "        train_df = pd.read_csv('https://raw.githubusercontent.com/wpbs/workshop/master/train.csv')\n",
    "        test_df = pd.read_csv('https://raw.githubusercontent.com/wpbs/workshop/master/test.csv')\n",
    "        \n",
    "        train_df = train_df.drop(['Ticket', 'Cabin', 'Name', 'Age', 'PassengerId', 'Parch', 'SibSp'], axis=1)\n",
    "        test_df = test_df.drop(['Ticket', 'Cabin', 'Name', 'Age', 'Parch', 'SibSp'], axis=1)\n",
    "        \n",
    "        freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "        test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "        for dataset in [train_df, test_df]:\n",
    "            if is_string_dtype(dataset['Sex']):\n",
    "                dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "            if is_string_dtype(dataset['Embarked']):\n",
    "                dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "                dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "            if dataset['Fare'].dtype == np.float64:\n",
    "                dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "                dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "                dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "                dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "                dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "        \n",
    "        combine = [train_df, test_df]\n",
    "        \n",
    "        train_orig_df = pd.read_csv('https://raw.githubusercontent.com/wpbs/workshop/master/train.csv')\n",
    "        test_orig_df = pd.read_csv('https://raw.githubusercontent.com/wpbs/workshop/master/test.csv')\n",
    "        \n",
    "        original_combine = [train_orig_df, test_orig_df]\n",
    "        \n",
    "        return train_df, test_df, combine, original_combine, train_orig_df, test_orig_df\n",
    "    \n",
    "    def clear_features(self, train_df, test_df, combine, feature_name):\n",
    "        if feature_name in train_df.columns:\n",
    "            train_df = train_df.drop([feature_name], axis=1)\n",
    "        if feature_name in test_df.columns:\n",
    "            test_df = test_df.drop([feature_name], axis=1)\n",
    "        combine = [train_df, test_df]\n",
    "        \n",
    "        return train_df, test_df, combine\n",
    "        \n",
    "    def apply_naivebayes(self, X_train, Y_train, X_test):\n",
    "        gaussian = GaussianNB()\n",
    "        gaussian.fit(X_train, Y_train)\n",
    "        Y_pred = gaussian.predict(X_test)\n",
    "        acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"Naive bayes score: \" + str(acc_gaussian))\n",
    "        return acc_gaussian\n",
    "    \n",
    "    def apply_logit(self, X_train, Y_train, X_test):\n",
    "        logreg = LogisticRegression()\n",
    "        logreg.fit(X_train, Y_train)\n",
    "        Y_pred = logreg.predict(X_test)\n",
    "        acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"Logit score: \" + str(acc_log))\n",
    "        return acc_log\n",
    "        \n",
    "    def apply_svm(self, X_train, Y_train, X_test):\n",
    "        svm = SVC()\n",
    "        svm.fit(X_train, Y_train)\n",
    "        Y_pred = svm.predict(X_test)\n",
    "        acc_svm = round(svm.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"SVM score: \" + str(acc_svm))\n",
    "        return acc_svm\n",
    "        \n",
    "    def apply_knn(self, X_train, Y_train, X_test):\n",
    "        knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "        knn.fit(X_train, Y_train)\n",
    "        Y_pred = knn.predict(X_test)\n",
    "        acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"KNN score: \" + str(acc_knn))\n",
    "        return acc_knn\n",
    "        \n",
    "    def apply_perceptron(self, X_train, Y_train, X_test):\n",
    "        perceptron = Perceptron(max_iter=5, tol=None)\n",
    "        perceptron.fit(X_train, Y_train)\n",
    "        Y_pred = perceptron.predict(X_test)\n",
    "        acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"Perceptron score: \" + str(acc_perceptron))\n",
    "        return acc_perceptron\n",
    "        \n",
    "    def apply_linear_svc(self, X_train, Y_train, X_test):\n",
    "        linear_svc = LinearSVC()\n",
    "        linear_svc.fit(X_train, Y_train)\n",
    "        Y_pred = linear_svc.predict(X_test)\n",
    "        acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"Linear SVC score: \" + str(acc_linear_svc))\n",
    "        return acc_linear_svc\n",
    "        \n",
    "    def apply_sgd(self, X_train, Y_train, X_test):\n",
    "        sgd = SGDClassifier(max_iter=5, tol=None)\n",
    "        sgd.fit(X_train, Y_train)\n",
    "        Y_pred = sgd.predict(X_test)\n",
    "        acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"SGD score: \" + str(acc_sgd))\n",
    "        return acc_sgd\n",
    "    \n",
    "    def apply_decisiontree(self, X_train, Y_train, X_test):\n",
    "        decision_tree = DecisionTreeClassifier()\n",
    "        decision_tree.fit(X_train, Y_train)\n",
    "        Y_pred = decision_tree.predict(X_test)\n",
    "        acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"Decision tree score: \" + str(acc_decision_tree))\n",
    "        return acc_decision_tree\n",
    "    \n",
    "    def apply_randomforest(self, X_train, Y_train, X_test, n_estimators=100):\n",
    "        random_forest = RandomForestClassifier(n_estimators)\n",
    "        random_forest.fit(X_train, Y_train)\n",
    "        Y_pred = random_forest.predict(X_test)\n",
    "        random_forest.score(X_train, Y_train)\n",
    "        acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "        print(\"Random forest score: \" + str(acc_random_forest))\n",
    "        return acc_random_forest\n",
    "\n",
    "\n",
    "h = Helpers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na een paar seconden komt de tekst weer in beeld. Test of alles goed is gegaan dit door hieronder de cel uit te voeren op de zelfde manier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als het goed is verandert in de linkerkolom `In[*]` in `In[<getal>]`. Dit wil zeggen dat de code correct is uitgevoerd en klaar is. De output moet iets zijn als `<__main__.Helpers at 0x178ba83ec18>`\n",
    "\n",
    "## Stap 2 - inlezen van de data\n",
    "\n",
    "De data is al gesplitst in een `train.csv` en een `test.csv` bestand. Voer onderstaande code in om de data in te lezen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _df staat voor 'data frame'\n",
    "train_df = pd.read_csv('https://raw.githubusercontent.com/wpbs/workshop/master/train.csv')\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/wpbs/workshop/master/test.csv')\n",
    "\n",
    "# In sommige gevallen is het handig om zowel train als testdata te gebruiken \n",
    "# maar let op dat (volledige) rijen test niet gebruikt worden als trainingsdata!\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 3 - inspecteren van de data\n",
    "\n",
    "### Beschikbare kolommen\n",
    "\n",
    "Om een beeld te krijgen van de beschikbare data, kunnen we de kolommen opvragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voorbeelden van categorische kolommen:\n",
    "- Survived\n",
    "- Sex\n",
    "- Embarked\n",
    "- Pclass\n",
    "\n",
    "Voorbeelden van numerieke kolommen:\n",
    "- Age\n",
    "- Fare\n",
    "- SibSp (Number of Siblings/Spouses Aboard)\n",
    "- Parch (Number of Parents/Children Aboard)\n",
    "\n",
    "### Eerste rijen\n",
    "\n",
    "Om een idee te krijgen van de data kunnen we de eerste rijen bekijken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments worden niet uitgevoerd\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laatste rijen\n",
    "En de laatste rijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatypes\n",
    "Wat voor datatypes hebben we het over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "print('_'*40)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kun je bijvoorbeeld zien dat Age 714 entries heeft: van zoveel passagiers was de leeftijd bekend. En dat Embarked 889 entries heeft wil zeggen dat 2 passagiers nooit aan boord gekomen zijn. Zij moeten het dus sowieso overleefd hebben.\n",
    "\n",
    "### Globale statistieken\n",
    "Om een idee te krijgen van de gehele dataset is het handig om een `.describe()` te gebruiken. Dit geeft per kolom (feature) de aantallen, gemiddelde, min, max, etcetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merk op dat hier enkel numerieke waarden in opgenomen zijn. Voor categorische variabelen geeft dit meer informatie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met deze globale informatie is het mogelijk om combinaties van features te bekijken om zo verbanden te ontdekken:\n",
    "\n",
    "## Stap 4 - data analyse\n",
    "\n",
    "### Groeperen\n",
    "\n",
    "Wat is de relatie tussen de klasse en de overlevingskans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En die van het geslacht?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En andere relaties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vul hier zelf een andere <feature> in en bekijk de relaties\n",
    "# train_df[[\"<feature>\", \"Survived\"]].groupby(['<feature>'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafieken\n",
    "Om meer inzicht in de relaties te krijgen is het handig om plots te maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 5 - feature constructie (skip)\n",
    "\n",
    "In de dataset zitten al een aantal features (kolommen). Op basis van de gevonden inzichten uit de data analyse kunnen we nu nieuwe of verbeterde features maken die het model zullen verbeteren. Denk hierbij aan features waar ontbrekende waarden gecorrigeerd zijn. Om het effect hiervan te kunnen zien gaan we eerst een (basis)model trainen\n",
    "\n",
    "## Stap 6 - basismodel trainen\n",
    "\n",
    "### Data klaarzetten\n",
    "\n",
    "Om een basismodel te trainen verwijderen we het label (\"Survived\") uit de trainingset, want het is valsspelen wanneer we die 1:1 in de input data hebben zitten wanneer we die willen voorspellen, én in de testset zit deze natuurlijk niet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voor het maken van een eerste model, laten we een aantal (bijvoorbeeld) categorische features buiten beschouwing\n",
    "train_df = train_df.drop(['Ticket', 'Cabin', 'Name', 'Age', 'PassengerId', 'Parch', 'SibSp'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin', 'Name', 'Age', 'Parch', 'SibSp'], axis=1)\n",
    "\n",
    "# Hier combineren we de twee dataframes zodat we hier gemakkelijk overheen kunnen itereren in vervolgstappen\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "for dataset in combine:\n",
    "    if is_string_dtype(dataset['Sex']):\n",
    "        dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "    if is_string_dtype(dataset['Embarked']):\n",
    "        dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "        dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    if dataset['Fare'].dtype == np.float64:\n",
    "        dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "        dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "        dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "        dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "        dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df[\"Survived\"]\n",
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "print(\"Trainingset (aantal rijen, aantal features): \" + str(X_train.shape))\n",
    "print(\"Testset     (aantal rijen, aantal features): \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trainen\n",
    "\n",
    "We beginnen met het trainen van een naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je kan zien is een score van 75% beter dan de gokkans (50%) en kunnen we hiermee starten met het verder verbeteren van het model\n",
    "\n",
    "## Stap X - analyse / Stap X+1 - feature constructie\n",
    "\n",
    "Voeg hieronder verdere analyses toe (waar nodig) om de data beter te begrijpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gebruik dit om weer terug te gaan naar de dataset/features in het basismodel\n",
    "train_df, test_df, combine, original_combine, original_train_df, original_test_df = h.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kies hieronder welke (extra) features of bewerkingen je wel of niet wil gebruiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vervang False door True om deze feature constructie mee te nemen\n",
    "if False:\n",
    "    # Dit geeft een overzicht van de verdeling tussen de title en het geslacht\n",
    "    print(pd.crosstab(original_train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False), train_df['Sex']))\n",
    "    \n",
    "    # Vul hieronder de mapping in hoe dat de titles vervangen moeten worden\n",
    "    replacements = {\n",
    "        'Lady': 'Overige',\n",
    "        'Countess': 'Overige',\n",
    "        # Vul hier nog aanvullende mappings aan\n",
    "    }\n",
    "    \n",
    "    # Gebruik de mapping om de nieuwe feature te maken\n",
    "    title_mapping = {\n",
    "        \"Mr\": 1,\n",
    "        \"Miss\": 2,\n",
    "        \"Mrs\": 3,\n",
    "        \"Master\": 4,\n",
    "        \"Overige\": 5\n",
    "    }\n",
    "    \n",
    "    # Title => de titel van de persoon opgedeeld in 'title_mapping'\n",
    "    train_df, test_df, combine = h.add_title(train_df, test_df, original_train_df, original_test_df, combine, replacements, title_mapping)\n",
    "else:\n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vervang False door True om deze feature constructie mee te nemen\n",
    "if False:\n",
    "    # AgeBinned => de leeftijd opgedeeld in bins\n",
    "    train_df, test_df, combine = h.add_age_binned(train_df, test_df, original_train_df, original_test_df, combine)\n",
    "else:\n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'AgeBinned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vervang False door True om deze feature constructie mee te nemen\n",
    "if False:\n",
    "    # FamilySize => grootte van de familie waarmee gereisd werd\n",
    "    train_df, test_df, combine = h.add_family_size(train_df, test_df, original_train_df, original_test_df, combine)\n",
    "else:\n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'FamilySize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vervang False door True om deze feature constructie mee te nemen\n",
    "if False:\n",
    "    # IsAlone => indicatie of de persoon alleen reisde of met familie\n",
    "    train_df, test_df, combine = h.add_is_alone(train_df, test_df, original_train_df, original_test_df, combine)\n",
    "else:\n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'IsAlone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vervang False door True om deze feature constructie mee te nemen\n",
    "if False:\n",
    "    # Age*Class => het product van de leeftijd en de class waarin gereisd werd\n",
    "    train_df, test_df, combine = h.add_age_times_class(train_df, test_df, original_train_df, original_test_df, combine)\n",
    "else:\n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'Age*Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vervang False door True om deze feature constructie mee te nemen\n",
    "if False:\n",
    "    # NameLength => de lengte van de naam\n",
    "    train_df['NameLength'] = original_train_df.Name.str.len()\n",
    "    test_df['NameLength'] = original_train_df.Name.str.len()\n",
    "else:\n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'NameLength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vervang False door True om deze feature constructie mee te nemen\n",
    "if False:\n",
    "    # Siblings/Spouses => aantal neefjes/nichtjes aan boord\n",
    "    train_df['temp'] = original_train_df['SibSp']\n",
    "    train_df.loc[train_df.temp.isnull(), 'temp'] = 0\n",
    "    \n",
    "    test_df['temp'] = original_test_df['SibSp']\n",
    "    test_df.loc[test_df.temp.isnull(), 'temp'] = 0    \n",
    "    \n",
    "    train_df['NumSiblingsSpouses'] = train_df.temp.astype(int)\n",
    "    test_df['NumSiblingsSpouses'] = test_df.temp.astype(int)\n",
    "    combine = [train_df, test_df]\n",
    "    \n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'temp')\n",
    "else:\n",
    "    train_df, test_df, combine = h.clear_features(train_df, test_df, combine, 'NumSiblingsSpouses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verzin hier eventueel zelf nog andere features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verzin hier eventueel zelf nog andere features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verzin hier eventueel zelf nog andere features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap X+2 - model trainen\n",
    "\n",
    "Na het aanpassen van de features kun je je model opnieuw trainen om te zien of het beter is geworden of niet.\n",
    "\n",
    "Voor het gemak hebben we het trainen van het model in 1 functie gestopt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.copy().drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.copy().drop(\"PassengerId\", axis=1).copy()\n",
    "h.apply_naivebayes(X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook andere algoritmen zijn beschikbaar, hier kun je zelf uit kiezen `h.apply_<algo>(X_train, Y_train, X_test)`:\n",
    "- logit (Logistische Regressie)\n",
    "- svm (Support Vector Machine)\n",
    "- knn (K nearest neighboor)\n",
    "- perceptron\n",
    "- linear_svc\n",
    "- sgd (Stogastic Gradient Descent)\n",
    "- decisiontree (beslisboom)\n",
    "- randomforest (combinatie van meerdere decision trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.apply_<algo>(X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap [laatste] - eindscore\n",
    "\n",
    "Wat is de hoogste gehaalde score? En hoe heb je deze kunnen verbeteren ten opzichte van het basismodel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
